\input{../latex/shared}

\renewcommand{\course}{Optimization Algorithms}
\renewcommand{\coursepicture}{optim}
\renewcommand{\coursedate}{Winter 2024/25}
\renewcommand{\exnum}{Weekly Exercise 4}

\exercises

\excludecomment{solution}

\exercisestitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Minimalistic Log Barrier}

Consider the 1D function, $x\in\RRR$,
$$f_\mu(x) = -x - \mu\log(-x)$$
(Note: This is the log barrier function for the problem $\min_{x\in\RRR} -x \st x \le 0$.)

\begin{enumerate}
	\item Plot the function for varying $\mu=1,0.5,0.1$.
	
	\item Analytically find the mimimum $x^*(\mu) = \argmin_x f_\mu(x)$ as a function of $\mu$.
	
	\item Prove that $\lim_{\mu\to 0} x^*(\mu) = 0$.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Dual Update in Augmented Lagrangian}

The squared penalty approach to solving an equality constrained optimization problem minimizes in each inner loop:
\begin{align}
\min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 ~. \label{eqLB1}
\end{align}

The Augmented Lagrangian method adds a Lagrangian term and minimizes in each inner loop:
\begin{align}
\min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 + \sum_{i=1}^m \l_i h_i(x)
~.\label{eqLB2}
\end{align}

Assume that we first minimize (\ref{eqLB1}) such that we end up at a minimum $\bar{x}$.

Now prove that, under the assumption
that the gradients $\na f(x)$ and $\na h(x)$ are (locally) constant, setting $\l_i = 2\mu h_i(\bar{x})$ will ensure that the minimum of (\ref{eqLB2}) fulfills the constraints
$h(x)=0$.

%% Tip: Compare the. Think about how the gradient that arises from
%% the penalty in (\ref{eqLB1}) is now generated via the $\l_i$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \exsection{Alternative Barriers \& Penalties}

%% Propose 2 alternative barrier functions to the log barrier, and 2 alternative penalty
%% functions to square penalties.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Gradient descent with matrices}

(This exercise goes beyond the context of the lecture, but further trains you in dealing with derivatives and gradient descent when the decision variable is a matrix.)

One way to derive a gradient is through the Taylor approximation
\begin{align*}
	f(w+h) \approx f(w) + \langle \delta, h \rangle
\end{align*}
where $\delta$ is the gradient and $\langle \delta, h \rangle = \delta^Th$ the standard scalar product. Now assume that $w$ is not a vector, but a matrix $W\in\mathbb{R}^{n\times m}$ and let $f(W) = \lVert WX - Y\rVert^2_F$ with $X, Y$ matrices of appropriate sizes and $\lVert\cdot \rVert_F$ the Frobenius norm. What is the $D$ in
\begin{align*}
	f(W+H) \approx f(W) + \langle D, H \rangle_F
\end{align*}
and how does a gradient step look like?

Tips: $\langle A, B \rangle_F = \text{tr}(A^TB)$



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exerfoot
