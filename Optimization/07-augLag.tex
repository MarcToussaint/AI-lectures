\input{../latex/shared}

\renewcommand{\course}{Optimization Algorithms}
\renewcommand{\coursepicture}{optim}
\renewcommand{\coursedate}{Winter 2024/25}

\renewcommand{\topic}{Augmented Lagrangian}
\renewcommand{\keywords}{squared penalties, Augmented Lagrangian}

\slides

\providecommand{\ninc}{\r_\nu^+}

\slidestitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Squared penalty method}
\slide{Squared Penalty Method}{

%% \item This is perhaps the simplest approach

\item To solve the original problem
$$\min_x~ f(x) \st g(x)\le 0,~ h(x)=0$$
we define the unconstrained \emph{inner} problem
$$\min_x S(x,\mu,\nu)\comma S(x,\mu,\nu) = f(x) + \mu \sum_i [g_i(x)>0]~ g_i(x)^2 + \nu \sum_j h_j(x)^2$$

~

\begin{algo}
\Require initial $x\in\RRR^n$, functions $f(x), g(x), h(x)$, tolerances $\t$, $\e$, parameters (defaults: $\minc=\ninc=10, \mu_0=\nu_0=1$)
\Ensure $x$
\State initialize $\mu=\mu_0$, $\nu=\nu_0$
\Repeat
\State solve unconstrained problem $x \gets \argmin_x S(x,\mu,\nu)$
\State $\mu \gets \minc \mu$,~ $\nu \gets \ninc \nu$
\Until $|\D x| \le\t$ and $\forall_{i,j}:~ g_i(x)\le\e, |h_i(x)|\le\e$ repeatedly
\end{algo}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Squared Penalty Method}{

\item Note: Here we increase $\mu$ and $\nu$ gradually

\item Pro:
\begin{items}
\item Very simple
\item Quadratic penalties $\to$ good conditioning for Newton methods $\to$ efficient convergence
\end{items}

\item Con:
\begin{items}
\item Will always lead to \emph{some} violation of constraints
\item Conditioning for very large $\mu,\nu$
\end{items}

\mypause

\item Better ideas:
\begin{items}
\item Add an out-pushing gradient/force $-\na g_i(x)$ for every constraint $g_i(x)>0$ that is violated
\item Ideally, the out-pushing gradient mixes with $-\na f(x)$ exactly consistent to ensure stationarity
\end{items}

\cen{$\to$ \emph{Augmented Lagrangian}}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Augmented Lagrangian method}
\slide{Augmented Lagrangian}{

{\small (We can introduce this is a self-contained manner, without yet
defining the ``Lagrangian'')}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Augmented Lagrangian}{

{\small
\item We first consider an \emph{equality} constraint before
addressing inequalities

}

\item To solve the original problem
$$\min_x~ f(x) \st h(x)= 0$$
we define the unconstrained \emph{inner} problem
\begin{align}
\min_x~ A(x,\k,\nu)\comma A(x,\k,\nu) = f(x) + \sum_j \k_j
h_j(x) + \nu \sum_j h_j(x)^2 \label{eqInner}
\end{align}

\item Note:
\begin{items}
\item The gradient $\na h_j(x)$ is always orthogonal to the constraint

\item By tuning $\k_j$ we can induce a ``pushing force'' $-\k_j \na
   h_j(x)$ ~ (cp.\ KKT stationarity!)

\item Each term $\nu h_j(x)^2$ penalizes as before, and ``pushes'' with $-2\nu h_j(x) \na h_j(x)$
\end{items}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Augmented Lagrangian}{

\item The approach:
\begin{items}
\item First minimize (\ref{eqInner}) for $\k_j=0$ and some $\nu$ ~$\leadsto$~ this will lead to a (slight) penalty
   $\nu h_j(x)^2$

\item Then \emph{choose $\k_j$ to generate exactly the
   gradient that was previously generated by the penalty}
\end{items}

\pause

\item Let's look at the gradients at the optimum $\min_x A(x,\k,\nu)$:
\begin{align*}
x'
 &= \argmin_x~ f(x)
 + \sum_j \k_j h_j(x)
 + \nu \sum_j h_j(x)^2 \\
\To \quad
0 &= \na f(x')
 + \sum_j \k_j \na h_j(x')
 + \nu \sum_j 2 h_j(x') \na h_j(x')
\end{align*}
{\tiny (Describes the force balance between $f$ pulling, penalties pushing, and Lagrange term pushing)

}

\pause

\item \defn{Augmented Lagrangian Update}: Update $\k$'s for the next iteration to be:
\begin{align*}
\sum_j \k_j^\new \na h_j(x')
 &\overset{!}=
 \sum_j \k_j^\old \na h_j(x')
 + \nu \sum_j 2 h_j(x') \na h_j(x') \\
\k_j^\new
 &= \k_j^\old + 2 \nu h_j(x')
\end{align*}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% \begin{algo}
%% \Require initial $x\in\RRR^n$, functions $f(x), h(x), \na f(x), \na
%% h(x)$, tol.\ $\t$, $\e$, parameters (defaults: $\minc=1, \nu_0=1$)
%% \Ensure $x$
%% \State initialize $\nu=\nu_0$, $\k_j=0$
%% \Repeat
%% \State find $x \gets \argmin_x f(x) + \nu \sum_j h_j(x)^2 + \sum_j \l_j h_j(x)$
%% \State $\forall_j:~ \l_j \gets \l_j + 2 \nu h_j(x')$
%% \State optionally, $\nu \gets \minc \nu$
%% \Until $|\D x| < \t$ and $|h_j(x)|<\e$
%% \end{algo}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{}{

\item Why this adaptation of $\k_j$ is elegant:

\begin{items}
\item We do \emph{not} have to take the penalty limit $\nu\to\infty$ but
   still can have \emph{exact} constraints

\item[$\to$] Unlike log-barrier and sqr penalty, the method \emph{does not have to increase weights of penalties/barriers}, and \emph{does not lead to extreme conditioning of the Hessian}

\item If $f$ and $h$ were linear ($\na f$ and $\na h_j$ constant), the
   updated $\k_j$ is \emph{exactly right}: In the next iteration we
   would exactly hit the constraint (by construction)

%% \item The penalty term is like a \emph{measuring device} for the necessary
%%    ``pushing force'', which is generated by the
%%    Lagrange term in the next iteration

%% \item The $\k_j$ are very meaningful: they give the force/gradient that a
%%    constraint exerts on the solution
\end{items}

~\pause

\item The Augmented Lagrangian handles equality constraints very efficiently

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Augmented Lagrangian with Inequalities}
\slide{Augmented Lagrangian with Inequalities}{

\small

\item To solve the original problem
$$\min_x~ f(x) \st g(x)\le 0,~ h(x)=0$$
we define the unconstrained inner problem, $\min_x ...$
$$A(x,\l,\k,\mu,\n) = f(x)
 + \sum_i \l_i g_i(x)
 + \mu \sum_i [g_i(x)\ge 0 \vee \l_i>0]~ g_i(x)^2
 + \sum_j \k_j h_j(x)
 + \nu \sum_j h_j(x)^2
$$


\item An inequality is either \defn{active} or \defn{inactive}:
\begin{items}
\item When active ($g_i(x)\ge 0 \vee \l_i>0$) we aim for equality
   $g_i(x)=0$

\item When inactive ($g_i(x)< 0 \wedge \l_i=0$) we don't penalize/augment

\item $\l_i$ are zero or positive, but never negative
\end{items}

\item After each inner optimization, we use the \defn{Augmented Lagrangian dual updates}:
\begin{align*}
\l_i \gets \max(\l_i + 2 \mu g_i(x'), 0) \comma \k_j \gets \k_j + 2 \nu h_j(x')~.
\end{align*}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Augmented Lagrangian}{

\begin{algo}[7]
\Require initial $x\in\RRR^n$, functions $f, g, h$, tolances $\t$, $\e$, parameters (defaults: $\minc=\ninc=1.2, \mu_0=\nu_0=1$)
\Ensure $x$
\State initialize $\mu=\mu_0$, $\nu=\nu_0$, $\l_i=0$, $\k_j=0$
\Repeat
\State solve unconstrained problem $x \gets \argmin_x A(x,\l,\k,\mu,\nu)$
\State $\forall_i:~ \l_i \gets \max(\l_i + 2 \mu g_i(x), 0)$,~ $\forall_j: \k_j \gets \k_j + 2 \nu h_j(x)$
\State optionally, $\mu \gets \minc \mu$, $\nu \gets \ninc \nu$
\Until $|\D x| < \t$ and $g_i(x)<\e$ and $|h_j(x)|<\e$ repeatedly
\end{algo}

~

\tiny

\item See also: M. Toussaint: A Novel Augmented Lagrangian Approach for Inequalities and Convergent Any-Time Non-Central Updates. e-Print arXiv:1412.4329, 2014.

\item Demo...

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Comments}{\label{lastpage}

\item We learnt about three core methods to tackle constrained optimization by repeated unconstrained optimization:
\begin{items}
\item Log barrier method
\item Squared penalty method (approximate only)
\item Augmented Lagrangian method
\end{items}

~

\item Next we discuss in more depth the Lagrangian, which will help to also introduce the primal-dual method

~

\item Later we discuss other methods, eg.\ Simplex, SQP

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slidesfoot
